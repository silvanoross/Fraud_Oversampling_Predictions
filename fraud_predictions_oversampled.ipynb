{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fraudulent Transactions\n",
    "\n",
    "In this notebook we will take fraud data, resample it and make comparisons between the fraud detector trained with over sampled data to the one trained with no over sampling.\n",
    "\n",
    "Data is taken from Kaggle:\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the `transaction_fraud_data.csv` file from the `Resources` folder into a Pandas DataFrame. Set the “id” column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the transaction_fraud_data.csv file into a PandasDataFrame.\n",
    "transaction_fraud_data = pd.read_csv(\n",
    "    Path(\"./creditcard.csv\"), \n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "transaction_fraud_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the features have already been engineered and normalized for this dataset. The 'Amount' column still needs to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>amount_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  amount_norm  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0     0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0    -0.342474  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0     1.160684  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0     0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0    -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make copy for manipulation\n",
    "fraud_df = transaction_fraud_data.copy()\n",
    "\n",
    "# replace Amount with normalized amount\n",
    "fraud_df[\"amount_norm\"] = (fraud_df[\"Amount\"] - fraud_df[\"Amount\"].mean()) / fraud_df[\"Amount\"].std()\n",
    "\n",
    "# drop original amount and time columns as they are not usfeul\n",
    "fraud_df.drop(columns=[\"Amount\", \"Time\"], inplace=True)\n",
    "\n",
    "fraud_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show how many of each class of fraud there is to see if we need to balance the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The  column 'fraud' is the thing you want to predict. \n",
    "# Class 0 indicates no-fraud trasactions and class 1 indicates fraudulent transactions\n",
    "# Using value_counts, how many fraudulent transactions are in this dataset?\n",
    "fraud_df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are very few cases of fraud. This tells us it is a very imabalanced dataset and we need to perform a resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target column should be the binary `fraud` column.\n",
    "target = fraud_df[\"Class\"]\n",
    "\n",
    "\n",
    "# The features column should be all of the features. \n",
    "features = fraud_df.drop(columns=[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>amount_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  amount_norm  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053     0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    -0.342474  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752     1.160684  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458     0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153    -0.073403  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split the features and target data into `training_features`, `testing_features`, `training_targets`, and `testing_targets` datasets by using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset using the train_test_split function with a 30% testing size and 70% training size\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample the data to get a more balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199021\n",
       "1    199021\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data which we will compare later\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count the distinct values to show a rebalanced dataset\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the training set has a balanced number of fraudelent events and none fraudulent events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Fit the Data to a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare 2 logistic regression models for over sampled and not oversampled data\n",
    "# Apply a random_state of 7 to the model\n",
    "lr_norm = LogisticRegression(random_state=7)\n",
    "lr_over_samp = LogisticRegression(random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit the training data to the model, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and save the logistic regression model using the training data for both training sets\n",
    "lr_norm = lr_norm.fit(X_train, y_train)\n",
    "lr_over_samp = lr_over_samp.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict both normal and over sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "pred_norm = lr_norm.predict(X_test)\n",
    "pred_over_samp = lr_over_samp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the accuracy score for the test dataset.\n",
    "accuracy_norm = accuracy_score(y_test, pred_norm)\n",
    "accuracy_over = accuracy_score(y_test, pred_over_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our regression model that was trained with the normal data is 0.9992275552122467\n",
      "The accuracy of our regression model that was trained with over sampled data is 0.9744039886239949\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of our regression model that was trained with the normal data is {accuracy_norm}\")\n",
    "print(f\"The accuracy of our regression model that was trained with over sampled data is {accuracy_over}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting finding. The accuracy of the regular dataset was higher than the oversampled dataset in this case. There may have been a sufficient number of samples in the regular dataset that oversampling was unecessary and actually harmed our model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a decision tree and find the most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the tree is 0.999204147794436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create tree instance with default parameters\n",
    "tree = DecisionTreeClassifier()\n",
    "# fit tree to data\n",
    "tree.fit(X_train, y_train)\n",
    "# make predictions\n",
    "tree_pred = tree.predict(X_test)\n",
    "# get accuracy \n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(f\"The accuracy of the tree is {tree_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='importance', ylabel='feature'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# get columns names\n",
    "col_names_full = list(X_train.columns)\n",
    "df_var_imp = pd.DataFrame({\"feature\": col_names_full, \n",
    "                           \"importance\": tree.feature_importances_})\n",
    "df_var_imp.sort_values(by=\"importance\", ascending=False, inplace=True)\n",
    "\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_var_imp.head(15), color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was going to assume that amount would have a higher feature importance when detecting fraud, but it looks like the V17 feature is just about the most important feature. Unfortunately, this dataset did not have any of the actual information associated with the columns. It could be due to sensitive information or that these columns were acquired from principal component analysis and don't have actual names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
